{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Autonomous_submarine_gate.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickchak21/Images_Model_Gate_Detection/blob/master/Autonomous_submarine_gate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V8-yl-s-WKMG"
      },
      "source": [
        "# Autonomous Submarine Gate Detection Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3cIrseUv6WKz"
      },
      "source": [
        "Welcome to the [Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection). This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VrJaG0cYN9yh"
      },
      "source": [
        "> **Important**: This tutorial is to help you through the first step towards using [Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection) to build models. If you just just need an off the shelf model that does the job, see the [TFHub object detection example](https://colab.sandbox.google.com/github/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kFSqkTCdWKMI"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "awjrpqy-6MaQ"
      },
      "source": [
        "Important: If you're running on a local machine, be sure to follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md). This notebook includes only what's necessary to run in Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p3UGXxUii5Ym"
      },
      "source": [
        "### Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hGL97-GXjSUw",
        "colab": {}
      },
      "source": [
        "!pip install -U --pre tensorflow==\"1.*\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n_ap_s9ajTHH"
      },
      "source": [
        "Make sure you have `pycocotools` installed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bg8ZyA47i3pY",
        "colab": {}
      },
      "source": [
        "!pip install pycocotools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-vsOL3QR6kqs"
      },
      "source": [
        "Get `tensorflow/models` or `cd` to parent directory of the repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ykA0c-om51s1",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O219m6yWAj9l"
      },
      "source": [
        "Compile protobufs and install the object_detection package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU53uTzD5y_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR3dYyK7Batj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv  -v TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/* models/research/object_detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PY41vdYYNlXc",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s62yJyQUcYbp",
        "colab": {}
      },
      "source": [
        "%%bash \n",
        "cd models/research\n",
        "pip install ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho7hIvUZDIqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pillow\n",
        "!pip install lxml\n",
        "!pip install Cython\n",
        "!pip install contextlib2\n",
        "!pip install jupyter\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY72PqXWIPJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install protobuf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4vnI0lo5SL-",
        "colab_type": "text"
      },
      "source": [
        "Loading training and testing images and labels, getting rid of old train/test images and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uPHOKNWI-As",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/nickchak21/Images_Model_Gate_Detection.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97b17VyWb-id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -uq \"Images_Model_Gate_Detection/approach1_frames_train.zip\" -d \"models/research/object_detection/images/train\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnHsxySxdWYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -uq \"Images_Model_Gate_Detection/approach1_frames_test.zip\" -d \"models/research/object_detection/images/test\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf6-knzWdtjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls models/research/object_detection/images/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNtEgpxCeCJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm models/research/object_detection/images/train/*.JPG"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_w6CeIreV8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm models/research/object_detection/images/train/*.xml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CfcGgsWdx0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm models/research/object_detection/images/train/*.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJiBFcmpefhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv models/research/object_detection/images/train/approach1_frames_train/* models/research/object_detection/images/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4_-VBjPewo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rmdir models/research/object_detection/images/train/approach1_frames_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y21Y8U66fBx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm models/research/object_detection/images/test/*\n",
        "#!rm models/research/object_detection/images/test/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyxG-knjf083",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm models/research/object_detection/images/test/*.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RERTH4EIf7ZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv models/research/object_detection/images/test/approach1_frames_test/* models/research/object_detection/images/test\n",
        "!rmdir models/research/object_detection/images/test/approach1_frames_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ovv0bN4ffgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls models/research/object_detection/images/test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWJkcVzXjUwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm models/research/object_detection/images/train/frame341.jpg models/research/object_detection/images/train/frame354.jpg models/research/object_detection/images/train/frame335.jpg models/research/object_detection/images/train/frame336.jpg models/research/object_detection/images/train/frame352.jpg models/research/object_detection/images/train/frame347.jpg models/research/object_detection/images/train/frame337.jpg models/research/object_detection/images/train/frame343.jpg models/research/object_detection/images/train/frame338.jpg models/research/object_detection/images/train/frame334.jpg models/research/object_detection/images/train/frame339.jpg models/research/object_detection/images/train/frame356.jpg models/research/object_detection/images/train/frame340.jpg models/research/object_detection/images/train/frame350.jpg models/research/object_detection/images/train/frame344.jpg models/research/object_detection/images/train/frame346.jpg models/research/object_detection/images/train/frame342.jpg models/research/object_detection/images/train/frame355.jpg models/research/object_detection/images/train/frame349.jpg models/research/object_detection/images/train/frame345.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6kYAogAlcY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm models/research/object_detection/images/test/frame353.jpg models/research/object_detection/images/test/frame351.jpg models/research/object_detection/images/test/frame348.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjhiyFtlncvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -uq \"Images_Model_Gate_Detection/approach1_labels_train.zip\" -d \"models/research/object_detection/images/train\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGxyezXendCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -uq \"Images_Model_Gate_Detection/approach1_labels_test.zip\" -d \"models/research/object_detection/images/test\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7dNRP-2n3-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv models/research/object_detection/images/train/approach1_labels_train/* models/research/object_detection/images/train\n",
        "!mv models/research/object_detection/images/test/approach1_labels_test/* models/research/object_detection/images/test\n",
        "\n",
        "!rmdir models/research/object_detection/images/train/approach1_labels_train\n",
        "!rmdir models/research/object_detection/images/test/approach1_labels_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyGkLJswnoKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls models/research/object_detection/images/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCpk8D3FoXKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls models/research/object_detection/images/test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1OawDyZ5LNp",
        "colab_type": "text"
      },
      "source": [
        "Loading pre-trained model in correct directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMt-eNFM36ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l1Z4TO33_s5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -C models/research/object_detection -zxvf faster_rcnn_inception_v2_coco_2018_01_28.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxMegKPa5e0Y",
        "colab_type": "text"
      },
      "source": [
        "Deleting other extra files in object_detection directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwaYw6fr5l-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm models/research/object_detection/training/*\n",
        "!rm models/research/object_detection/inference_graph/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3izIJgQH7iq3",
        "colab_type": "text"
      },
      "source": [
        "Generate csv file for image labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8qw5v4Yg8sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pycat models/research/object_detection/xml_to_csv.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS7VkKpKhKFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile models/research/object_detection/xml_to_csv.py\n",
        "frames_less_200 = []\n",
        "frames_greater_200 = []\n",
        "\n",
        "for i in range(0,200):\n",
        "    frames_less_200.append('frame{}.jpg'.format(i))\n",
        "\n",
        "for i in range(200,365):\n",
        "    frames_greater_200.append('frame{}.jpg'.format(i))\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        # print(root.find('filename').text)\n",
        "        for member in root.findall('object'):\n",
        "            if root.find('filename').text in frames_less_200:\n",
        "                value = (root.find('filename').text,\n",
        "                        int(root.find('size')[0].text),\n",
        "                        int(root.find('size')[1].text),\n",
        "                        member[0].text,\n",
        "                        int(member[5][0].text),\n",
        "                        int(member[5][1].text),\n",
        "                        int(member[5][2].text),\n",
        "                        int(member[5][3].text)\n",
        "                        )\n",
        "            else:\n",
        "                value = (root.find('filename').text,\n",
        "                        int(root.find('size')[0].text),\n",
        "                        int(root.find('size')[1].text),\n",
        "                        member[0].text,\n",
        "                        int(member[4][0].text),\n",
        "                        int(member[4][1].text),\n",
        "                        int(member[4][2].text),\n",
        "                        int(member[4][3].text)\n",
        "                        )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "\n",
        "def main():\n",
        "    for folder in ['train','test']:\n",
        "        image_path = os.path.join('models/research/object_detection', ('images/' + folder))\n",
        "        xml_df = xml_to_csv(image_path)\n",
        "        xml_df.to_csv(('models/research/object_detection/images/' + folder + '_labels.csv'), index=None)\n",
        "        print('Successfully converted xml to csv.')\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYKtROBQocIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python models/research/object_detection/xml_to_csv.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPhCT7jdXQTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat models/research/object_detection/images/test_labels.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd0iNx1P--m4",
        "colab_type": "text"
      },
      "source": [
        "Generating TF Records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usCZp9AB-zwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pycat models/research/object_detection/generate_tfrecord.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI0ejwbO_XHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile models/research/object_detection/generate_tfrecord.py\n",
        "\n",
        "\"\"\"\n",
        "Usage:\n",
        "  # From tensorflow/models/\n",
        "  # Create train data:\n",
        "  python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record\n",
        "\n",
        "  # Create test data:\n",
        "  python generate_tfrecord.py --csv_input=images/test_labels.csv  --image_dir=images/test --output_path=test.record\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "flags = tf.app.flags\n",
        "flags.DEFINE_string('csv_input', '', 'Path to the CSV input')\n",
        "flags.DEFINE_string('image_dir', '', 'Path to the image directory')\n",
        "flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "# TO-DO replace this with label map\n",
        "def class_text_to_int(row_label):\n",
        "    if row_label == 'start_tick':\n",
        "        return 1\n",
        "    elif row_label == 'start_gate':\n",
        "        return 2\n",
        "    else:\n",
        "        None\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n",
        "    path = os.path.join(os.getcwd(), FLAGS.image_dir)\n",
        "    examples = pd.read_csv(FLAGS.csv_input)\n",
        "    grouped = split(examples, 'filename')\n",
        "    for group in grouped:\n",
        "        tf_example = create_tf_example(group, path)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n",
        "    print('Successfully created the TFRecords: {}'.format(output_path))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tf.app.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb2ywtTwAD72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python models/research/object_detection/generate_tfrecord.py --csv_input=models/research/object_detection/images/train_labels.csv --image_dir=models/research/object_detection/images/train --output_path=models/research/object_detection/train.record\n",
        "!python models/research/object_detection/generate_tfrecord.py --csv_input=models/research/object_detection/images/test_labels.csv --image_dir=models/research/object_detection/images/test --output_path=models/research/object_detection/test.record"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdNljrYJDoMu",
        "colab_type": "text"
      },
      "source": [
        "Create label map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwWdL2KGDpga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile models/research/object_detection/training/labelmap.pbtxt\n",
        "\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'start_tick'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 2\n",
        "  name: 'start_gate'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk5oROGjE09e",
        "colab_type": "text"
      },
      "source": [
        "Configure training pipeline (edit config file for pre-trained model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaBxjiQBE9OK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp models/research/object_detection/samples/configs/faster_rcnn_inception_v2_pets.config models/research/object_detection/training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0ZRdSFLZMcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp models/research/object_detection/samples/configs/faster_rcnn_inception_v2_pets.config models/research/object_detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MrHAZCVGc7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat models/research/object_detection/training/faster_rcnn_inception_v2_pets.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXrrcklwGdJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile models/research/object_detection/training/faster_rcnn_inception_v2_pets.config\n",
        "\n",
        "# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.\n",
        "# Users should configure the fine_tune_checkpoint field in the train config as\n",
        "# well as the label_map_path and input_path fields in the train_input_reader and\n",
        "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
        "# should be configured.\n",
        "\n",
        "model {\n",
        "  faster_rcnn {\n",
        "    num_classes: 2\n",
        "    image_resizer {\n",
        "      keep_aspect_ratio_resizer {\n",
        "        min_dimension: 600\n",
        "        max_dimension: 1024\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'faster_rcnn_inception_v2'\n",
        "      first_stage_features_stride: 16\n",
        "    }\n",
        "    first_stage_anchor_generator {\n",
        "      grid_anchor_generator {\n",
        "        scales: [0.25, 0.5, 1.0, 2.0]\n",
        "        aspect_ratios: [0.5, 1.0, 2.0]\n",
        "        height_stride: 16\n",
        "        width_stride: 16\n",
        "      }\n",
        "    }\n",
        "    first_stage_box_predictor_conv_hyperparams {\n",
        "      op: CONV\n",
        "      regularizer {\n",
        "        l2_regularizer {\n",
        "          weight: 0.0\n",
        "        }\n",
        "      }\n",
        "      initializer {\n",
        "        truncated_normal_initializer {\n",
        "          stddev: 0.01\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    first_stage_nms_score_threshold: 0.0\n",
        "    first_stage_nms_iou_threshold: 0.7\n",
        "    first_stage_max_proposals: 300\n",
        "    first_stage_localization_loss_weight: 2.0\n",
        "    first_stage_objectness_loss_weight: 1.0\n",
        "    initial_crop_size: 14\n",
        "    maxpool_kernel_size: 2\n",
        "    maxpool_stride: 2\n",
        "    second_stage_box_predictor {\n",
        "      mask_rcnn_box_predictor {\n",
        "        use_dropout: false\n",
        "        dropout_keep_probability: 1.0\n",
        "        fc_hyperparams {\n",
        "          op: FC\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.0\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            variance_scaling_initializer {\n",
        "              factor: 1.0\n",
        "              uniform: true\n",
        "              mode: FAN_AVG\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    second_stage_post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 0.0\n",
        "        iou_threshold: 0.6\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 300\n",
        "      }\n",
        "      score_converter: SOFTMAX\n",
        "    }\n",
        "    second_stage_localization_loss_weight: 2.0\n",
        "    second_stage_classification_loss_weight: 1.0\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  batch_size: 1\n",
        "  optimizer {\n",
        "    momentum_optimizer: {\n",
        "      learning_rate: {\n",
        "        manual_step_learning_rate {\n",
        "          initial_learning_rate: 0.0002\n",
        "          schedule {\n",
        "            step: 900000\n",
        "            learning_rate: .00002\n",
        "          }\n",
        "          schedule {\n",
        "            step: 1200000\n",
        "            learning_rate: .000002\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "    }\n",
        "    use_moving_average: false\n",
        "  }\n",
        "  gradient_clipping_by_norm: 10.0\n",
        "  fine_tune_checkpoint: \"models/research/object_detection/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt\"\n",
        "  from_detection_checkpoint: true\n",
        "  load_all_detection_checkpoint_vars: true\n",
        "  # Note: The below line limits the training process to 200K steps, which we\n",
        "  # empirically found to be sufficient enough to train the pets dataset. This\n",
        "  # effectively bypasses the learning rate schedule (the learning rate will\n",
        "  # never decay). Remove the below line to train indefinitely.\n",
        "  num_steps: 200000\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"models/research/object_detection/train.record\"\n",
        "  }\n",
        "  label_map_path: \"models/research/object_detection/training/labelmap.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  metrics_set: \"coco_detection_metrics\"\n",
        "  num_examples: 74\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"models/research/object_detection/test.record\"\n",
        "  }\n",
        "  label_map_path: \"models/research/object_detection/training/labelmap.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyiuG6KqZVGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile models/research/object_detection/faster_rcnn_inception_v2_pets.config\n",
        "\n",
        "# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.\n",
        "# Users should configure the fine_tune_checkpoint field in the train config as\n",
        "# well as the label_map_path and input_path fields in the train_input_reader and\n",
        "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
        "# should be configured.\n",
        "\n",
        "model {\n",
        "  faster_rcnn {\n",
        "    num_classes: 2\n",
        "    image_resizer {\n",
        "      keep_aspect_ratio_resizer {\n",
        "        min_dimension: 600\n",
        "        max_dimension: 1024\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'faster_rcnn_inception_v2'\n",
        "      first_stage_features_stride: 16\n",
        "    }\n",
        "    first_stage_anchor_generator {\n",
        "      grid_anchor_generator {\n",
        "        scales: [0.25, 0.5, 1.0, 2.0]\n",
        "        aspect_ratios: [0.5, 1.0, 2.0]\n",
        "        height_stride: 16\n",
        "        width_stride: 16\n",
        "      }\n",
        "    }\n",
        "    first_stage_box_predictor_conv_hyperparams {\n",
        "      op: CONV\n",
        "      regularizer {\n",
        "        l2_regularizer {\n",
        "          weight: 0.0\n",
        "        }\n",
        "      }\n",
        "      initializer {\n",
        "        truncated_normal_initializer {\n",
        "          stddev: 0.01\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    first_stage_nms_score_threshold: 0.0\n",
        "    first_stage_nms_iou_threshold: 0.7\n",
        "    first_stage_max_proposals: 300\n",
        "    first_stage_localization_loss_weight: 2.0\n",
        "    first_stage_objectness_loss_weight: 1.0\n",
        "    initial_crop_size: 14\n",
        "    maxpool_kernel_size: 2\n",
        "    maxpool_stride: 2\n",
        "    second_stage_box_predictor {\n",
        "      mask_rcnn_box_predictor {\n",
        "        use_dropout: false\n",
        "        dropout_keep_probability: 1.0\n",
        "        fc_hyperparams {\n",
        "          op: FC\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.0\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            variance_scaling_initializer {\n",
        "              factor: 1.0\n",
        "              uniform: true\n",
        "              mode: FAN_AVG\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    second_stage_post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 0.0\n",
        "        iou_threshold: 0.6\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 300\n",
        "      }\n",
        "      score_converter: SOFTMAX\n",
        "    }\n",
        "    second_stage_localization_loss_weight: 2.0\n",
        "    second_stage_classification_loss_weight: 1.0\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  batch_size: 1\n",
        "  optimizer {\n",
        "    momentum_optimizer: {\n",
        "      learning_rate: {\n",
        "        manual_step_learning_rate {\n",
        "          initial_learning_rate: 0.0002\n",
        "          schedule {\n",
        "            step: 900000\n",
        "            learning_rate: .00002\n",
        "          }\n",
        "          schedule {\n",
        "            step: 1200000\n",
        "            learning_rate: .000002\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "    }\n",
        "    use_moving_average: false\n",
        "  }\n",
        "  gradient_clipping_by_norm: 10.0\n",
        "  fine_tune_checkpoint: \"models/research/object_detection/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt\"\n",
        "  from_detection_checkpoint: true\n",
        "  load_all_detection_checkpoint_vars: true\n",
        "  # Note: The below line limits the training process to 200K steps, which we\n",
        "  # empirically found to be sufficient enough to train the pets dataset. This\n",
        "  # effectively bypasses the learning rate schedule (the learning rate will\n",
        "  # never decay). Remove the below line to train indefinitely.\n",
        "  num_steps: 200000\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"models/research/object_detection/train.record\"\n",
        "  }\n",
        "  label_map_path: \"models/research/object_detection/training/labelmap.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  metrics_set: \"coco_detection_metrics\"\n",
        "  num_examples: 74\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"models/research/object_detection/test.record\"\n",
        "  }\n",
        "  label_map_path: \"models/research/object_detection/training/labelmap.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU4oJuMTJXTR",
        "colab_type": "text"
      },
      "source": [
        "Running training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3mIWKUJTBOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!set PYTHONPATH=models;models/research;models/research/slim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIp547uOfH7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!models/research/setup.py build\n",
        "!models/research/setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFw4knlVUC5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile -a .bashrc\n",
        "export PYTHONPATH=\"$PYTHONPATH:models/research:models/research/slim\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE6bX1fbUsSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /bin/bash   \n",
        "!set -m\n",
        "!set PYTHONPATH=models;models/research;models/research/slim\n",
        "!set PATH=%PATH%;%PYTHONPATH%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtZ7SgtIVr2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ0fn1W8JYs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python models/research/object_detection/legacy/train.py --logtostderr --train_dir=models/research/object_detection/training/ --pipeline_config_path=models/research/object_detection/faster_rcnn_inception_v2_pets.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JAeYFS9L3G6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pycat /usr/local/lib/python3.6/dist-packages/object_detection/eval_util.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XSXQ4F6LBe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tf_slim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG1_K0A5nmjH",
        "colab_type": "text"
      },
      "source": [
        "Saving as frozen inference graph\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vABsRsIwY4Nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls models/research/object_detection/training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfmwQgU_Rc0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python models/research/object_detection/export_inference_graph.py --input_type image_tensor --pipeline_config_path models/research/object_detection/training/faster_rcnn_inception_v2_pets.config --trained_checkpoint_prefix models/research/object_detection/training/model.ckpt-36868 --output_directory models/research/object_detection/inference_graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALopgGjvSDKZ",
        "colab_type": "text"
      },
      "source": [
        "Mounting all info to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnShPVsqSGh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF-1YRDQSLaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/models/* '/content/gdrive/My Drive/Gate_Detection/models'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6tAOaM0ckWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls models/research/object_detection/inference_graph/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rwiZBnWRdO3",
        "colab_type": "text"
      },
      "source": [
        "Testing image and video data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDSiDyn1dqP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pycat models/research/object_detection/Object_detection_image.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GERB0Wzqfr14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aPoi4XveAFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile models/research/object_detection/Object_detection_image_frame89.py\n",
        "######## Image Object Detection Using Tensorflow-trained Classifier #########\n",
        "#\n",
        "# Author: Evan Juras\n",
        "# Date: 1/15/18\n",
        "# Description: \n",
        "# This program uses a TensorFlow-trained neural network to perform object detection.\n",
        "# It loads the classifier and uses it to perform object detection on an image.\n",
        "# It draws boxes, scores, and labels around the objects of interest in the image.\n",
        "\n",
        "## Some of the code is copied from Google's example at\n",
        "## https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\n",
        "\n",
        "## and some is copied from Dat Tran's example at\n",
        "## https://github.com/datitran/object_detector_app/blob/master/object_detection_app.py\n",
        "\n",
        "## but I changed it to make it more understandable to me.\n",
        "\n",
        "# Import packages\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "# Import utilites\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util\n",
        "\n",
        "# Name of the directory containing the object detection module we're using\n",
        "MODEL_NAME = 'inference_graph'\n",
        "IMAGE_NAME = 'images/test/frame89.jpg'\n",
        "\n",
        "# Grab path to current working directory\n",
        "CWD_PATH = os.getcwd()\n",
        "\n",
        "# Path to frozen detection graph .pb file, which contains the model that is used\n",
        "# for object detection.\n",
        "PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb')\n",
        "\n",
        "# Path to label map file\n",
        "PATH_TO_LABELS = os.path.join(CWD_PATH,'training','labelmap.pbtxt')\n",
        "\n",
        "# Path to image\n",
        "PATH_TO_IMAGE = os.path.join(CWD_PATH,IMAGE_NAME)\n",
        "\n",
        "# Number of classes the object detector can identify\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "# Load the label map.\n",
        "# Label maps map indices to category names, so that when our convolution\n",
        "# network predicts `5`, we know that this corresponds to `king`.\n",
        "# Here we use internal utility functions, but anything that returns a\n",
        "# dictionary mapping integers to appropriate string labels would be fine\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "# Load the Tensorflow model into memory.\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "    sess = tf.Session(graph=detection_graph)\n",
        "\n",
        "# Define input and output tensors (i.e. data) for the object detection classifier\n",
        "\n",
        "# Input tensor is the image\n",
        "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "# Output tensors are the detection boxes, scores, and classes\n",
        "# Each box represents a part of the image where a particular object was detected\n",
        "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "\n",
        "# Each score represents level of confidence for each of the objects.\n",
        "# The score is shown on the result image, together with the class label.\n",
        "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "\n",
        "# Number of objects detected\n",
        "num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "# Load image using OpenCV and\n",
        "# expand image dimensions to have shape: [1, None, None, 3]\n",
        "# i.e. a single-column array, where each item in the column has the pixel RGB value\n",
        "image = cv2.imread(PATH_TO_IMAGE)\n",
        "image_expanded = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Perform the actual detection by running the model with the image as input\n",
        "(boxes, scores, classes, num) = sess.run(\n",
        "    [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "    feed_dict={image_tensor: image_expanded})\n",
        "\n",
        "# Draw the results of the detection (aka 'visualize the results')\n",
        "\n",
        "vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "    image,\n",
        "    np.squeeze(boxes),\n",
        "    np.squeeze(classes).astype(np.int32),\n",
        "    np.squeeze(scores),\n",
        "    category_index,\n",
        "    use_normalized_coordinates=True,\n",
        "    line_thickness=8,\n",
        "    min_score_thresh=0.60)\n",
        "\n",
        "cv2.imwrite('/content/gdrive/My Drive/Gate_Detection/frame89_labeled.jpg', image)\n",
        "\n",
        "# All the results have been drawn on image. Now display the image.\n",
        "#cv2.imshow('Object detector', image)\n",
        "\n",
        "# Press any key to close the image\n",
        "#cv2.waitKey(0)\n",
        "\n",
        "# Clean up\n",
        "#cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4sd1qP9eeiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "cd models/research/object_detection\n",
        "python Object_detection_image_frame89.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia34ygPQrVU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r678JwWEq9j-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "mkdir models\n",
        "cd models\n",
        "mkdir research\n",
        "cd research\n",
        "mkdir object_detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUcYHAF0LT4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsEpnnn9qWE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/gdrive/My\\ Drive/Gate_Detection/models/research/object_detection/* '/content/models/research/object_detection'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGW8_0p5jNCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pycat models/research/object_detection/Object_detection_video.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65Yb-4lEj6TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/gdrive/My Drive/CS/CV Footage (Duke 2019)/alpha_073019_0900/approach2.mp4' 'models/research/object_detection'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAuhmBYvjiZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile models/research/object_detection/Object_detection_video_approach2.py\n",
        "######## Video Object Detection Using Tensorflow-trained Classifier #########\n",
        "#\n",
        "# Author: Evan Juras\n",
        "# Date: 1/16/18\n",
        "# Description: \n",
        "# This program uses a TensorFlow-trained classifier to perform object detection.\n",
        "# It loads the classifier and uses it to perform object detection on a video.\n",
        "# It draws boxes, scores, and labels around the objects of interest in each\n",
        "# frame of the video.\n",
        "\n",
        "## Some of the code is copied from Google's example at\n",
        "## https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\n",
        "\n",
        "## and some is copied from Dat Tran's example at\n",
        "## https://github.com/datitran/object_detector_app/blob/master/object_detection_app.py\n",
        "\n",
        "## but I changed it to make it more understandable to me.\n",
        "\n",
        "# Import packages\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "# Import utilites\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util\n",
        "\n",
        "#from cv2.cv import *\n",
        "\n",
        "# Name of the directory containing the object detection module we're using\n",
        "MODEL_NAME = 'inference_graph'\n",
        "VIDEO_NAME = 'approach2.mp4'\n",
        "\n",
        "# Grab path to current working directory\n",
        "CWD_PATH = os.getcwd()\n",
        "\n",
        "# Path to frozen detection graph .pb file, which contains the model that is used\n",
        "# for object detection.\n",
        "PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb')\n",
        "\n",
        "# Path to label map file\n",
        "PATH_TO_LABELS = os.path.join(CWD_PATH,'training','labelmap.pbtxt')\n",
        "\n",
        "# Path to video\n",
        "PATH_TO_VIDEO = os.path.join(CWD_PATH,VIDEO_NAME)\n",
        "\n",
        "# Number of classes the object detector can identify\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "# Load the label map.\n",
        "# Label maps map indices to category names, so that when our convolution\n",
        "# network predicts `5`, we know that this corresponds to `king`.\n",
        "# Here we use internal utility functions, but anything that returns a\n",
        "# dictionary mapping integers to appropriate string labels would be fine\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "# Load the Tensorflow model into memory.\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "    sess = tf.Session(graph=detection_graph)\n",
        "\n",
        "# Define input and output tensors (i.e. data) for the object detection classifier\n",
        "\n",
        "# Input tensor is the image\n",
        "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "# Output tensors are the detection boxes, scores, and classes\n",
        "# Each box represents a part of the image where a particular object was detected\n",
        "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "\n",
        "# Each score represents level of confidence for each of the objects.\n",
        "# The score is shown on the result image, together with the class label.\n",
        "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "\n",
        "# Number of objects detected\n",
        "num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "# Open video file\n",
        "video = cv2.VideoCapture(PATH_TO_VIDEO)\n",
        "\n",
        "ret, frame = video.read()\n",
        "height, width, layers = frame.shape\n",
        "\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
        "\n",
        "#label_video = cv2.VideoWriter('content/gdrive/My Drive/Gate_Detection/approach2.avi', 0, 1, (width,height))\n",
        "label_video = cv2.VideoWriter('approach2.avi', fourcc, fps, (width,height))\n",
        "\n",
        "while(video.isOpened()):\n",
        "\n",
        "    # Acquire frame and expand frame dimensions to have shape: [1, None, None, 3]\n",
        "    # i.e. a single-column array, where each item in the column has the pixel RGB value\n",
        "\n",
        "    print(\"Reading image\")\n",
        "\n",
        "    ret, frame = video.read()\n",
        "    frame_expanded = np.expand_dims(frame, axis=0)\n",
        "\n",
        "    print(\"Performing object detection\")\n",
        "\n",
        "    # Perform the actual detection by running the model with the image as input\n",
        "    #if frame_expanded is not None:\n",
        "    if ret == True:\n",
        "        (boxes, scores, classes, num) = sess.run(\n",
        "            [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "            feed_dict={image_tensor: frame_expanded})\n",
        "    else:\n",
        "        break\n",
        "    \n",
        "    print(\"Draw results\")\n",
        "\n",
        "    # Draw the results of the detection (aka 'visulaize the results')\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        frame,\n",
        "        np.squeeze(boxes),\n",
        "        np.squeeze(classes).astype(np.int32),\n",
        "        np.squeeze(scores),\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8,\n",
        "        min_score_thresh=0.60)\n",
        "\n",
        "    print(\"Write to video\")\n",
        "\n",
        "    # All the results have been drawn on the frame, so it's time to display it.\n",
        "    #cv2.imwrite('/content/gdrive/My Drive/Gate_Detection/approach1.jpg', frame)\n",
        "    #cv2.imshow('Object detector', frame)\n",
        "    label_video.write(frame)\n",
        "    \n",
        "    # Press 'q' to quit\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        print(\"Quit\")\n",
        "        break\n",
        "\n",
        "# Clean up\n",
        "label_video.release()\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzEszPGqk8kN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "cd models/research/object_detection\n",
        "python Object_detection_video_approach2.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z1gnnGNdhab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "cd models/research/object_detection/\n",
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJPwfqHFjzNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('models/research/object_detection/approach2.avi')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LBdjK2G5ywuc"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hV4P5gyTWKMI",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r5FNuiRPWKMN"
      },
      "source": [
        "Import the object detection module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4-IMl4b6BdGO",
        "colab": {}
      },
      "source": [
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RYPCiag2iz_q"
      },
      "source": [
        "Patches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mF-YlMl8c_bM",
        "colab": {}
      },
      "source": [
        "# patch tf1 into `utils.ops`\n",
        "utils_ops.tf = tf.compat.v1\n",
        "\n",
        "# Patch the location of gfile\n",
        "tf.gfile = tf.io.gfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cfn_tRFOWKMO"
      },
      "source": [
        "# Model preparation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X_sEBLpVWKMQ"
      },
      "source": [
        "## Variables\n",
        "\n",
        "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing the path.\n",
        "\n",
        "By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ai8pLZZWKMS"
      },
      "source": [
        "## Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zm8xp-0eoItE",
        "colab": {}
      },
      "source": [
        "def load_model(model_name):\n",
        "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "  model_file = model_name + '.tar.gz'\n",
        "  model_dir = tf.keras.utils.get_file(\n",
        "    fname=model_name, \n",
        "    origin=base_url + model_file,\n",
        "    untar=True)\n",
        "\n",
        "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
        "\n",
        "  model = tf.saved_model.load(str(model_dir))\n",
        "  model = model.signatures['serving_default']\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_1MVVTcLWKMW"
      },
      "source": [
        "## Loading label map\n",
        "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hDbpHkiWWKMX",
        "colab": {}
      },
      "source": [
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oVU3U_J6IJVb"
      },
      "source": [
        "For the sake of simplicity we will test on 2 images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmgbJ_2FBnqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jG-zn5ykWKMd",
        "colab": {}
      },
      "source": [
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "!unzip -uq \"/content/drive/My Drive/approach1_frames.zip\" -d \"models/research/object_detection/test_images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDoXQ18xF4ox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/approach1_sample.zip\" -d \"models/research/object_detection/test_images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URAdjCw4G-1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/approach1_sample_saturated.zip\" -d \"models/research/object_detection/test_images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNUDM-iQH0O8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/approach1_sample_super_saturated.zip\" -d \"models/research/object_detection/test_images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvkaNaKzDFiq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRoOe9a7ECNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('models/research/object_detection/test_images')\n",
        "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
        "TEST_IMAGE_PATHS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS5gF5nEFDmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('models/research/object_detection/test_images/approach1_sample')\n",
        "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
        "TEST_IMAGE_PATHS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSTVF1JqG6t-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('models/research/object_detection/test_images/approach1_sample_saturated')\n",
        "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
        "TEST_IMAGE_PATHS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voHn_yi2IExS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('models/research/object_detection/test_images/appraoch1_sample_super_saturated')\n",
        "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
        "TEST_IMAGE_PATHS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bnT0cTpJrPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('models/research/object_detection/test_images/appraoch1_sample_super_saturated')\n",
        "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
        "TEST_IMAGE_PATHS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0tRwKgvDF67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('/content/drive/My Drive/Normal_Photo')\n",
        "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
        "TEST_IMAGE_PATHS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBztc2W9C1gR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd models/research/object_detection/test_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDPFPX4WC4tN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H0_1AGhrWKMc"
      },
      "source": [
        "# Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f7aOtOlebK7h"
      },
      "source": [
        "Load an object detection model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1XNT0wxybKR6",
        "colab": {}
      },
      "source": [
        "model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "detection_model = load_model(model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yN1AYfAEJIGp"
      },
      "source": [
        "Check the model's input signature, it expects a batch of 3-color images of type uint8: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CK4cnry6wsHY",
        "colab": {}
      },
      "source": [
        "print(detection_model.inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q8u3BjpMJXZF"
      },
      "source": [
        "And retuns several outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oLSZpfaYwuSk",
        "colab": {}
      },
      "source": [
        "detection_model.output_dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FZyKUJeuxvpT",
        "colab": {}
      },
      "source": [
        "detection_model.output_shapes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JP5qZ7sXJpwG"
      },
      "source": [
        "Add a wrapper function to call the model, and cleanup the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ajmR_exWyN76",
        "colab": {}
      },
      "source": [
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  output_dict = model(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "   \n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])      \n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "    \n",
        "  return output_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z1wq0LVyMRR_"
      },
      "source": [
        "Run it on each test image and show the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DWh_1zz6aqxs",
        "colab": {}
      },
      "source": [
        "def show_inference(model, image_path):\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = np.array(Image.open(image_path))\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "\n",
        "  display(Image.fromarray(image_np))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3a5wMHN8WKMh",
        "colab": {}
      },
      "source": [
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  show_inference(detection_model, image_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DsspMPX3Cssg"
      },
      "source": [
        "## Instance Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CzkVv_n2MxKC",
        "colab": {}
      },
      "source": [
        "model_name = \"mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28\"\n",
        "masking_model = load_model(\"mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0S7aZi8ZOhVV"
      },
      "source": [
        "The instance segmentation model includes a `detection_masks` output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vQ2Sj2VIOZLA",
        "colab": {}
      },
      "source": [
        "masking_model.output_shapes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AS57rZlnNL7W",
        "colab": {}
      },
      "source": [
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  show_inference(masking_model, image_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nLlmm9JojEKm",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzMvntydFxwI",
        "colab_type": "text"
      },
      "source": [
        "Training the autonomous submarine model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-2VuaBsF1Tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting xml files into model\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}